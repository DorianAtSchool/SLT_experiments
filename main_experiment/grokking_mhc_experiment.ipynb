{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Grokking + LLC with mHC (Manifold-Constrained Hyper-Connections)\n",
    "\n",
    "This notebook compares standard MLP vs MLP with mHC on the modular addition grokking task.\n",
    "\n",
    "## What is mHC?\n",
    "\n",
    "**mHC = Manifold-Constrained Hyper-Connections** (DeepSeek, Dec 2025)\n",
    "\n",
    "Instead of standard residual connections `x_{l+1} = x_l + F(x_l)`, mHC uses:\n",
    "\n",
    "```\n",
    "x_{l+1} = H_res @ x_l + H_post^T @ F(H_pre @ x_l)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `H_res`: **Doubly stochastic matrix** (rows & cols sum to 1) via Sinkhorn-Knopp\n",
    "- `H_pre`, `H_post`: Non-negative mixing matrices via softmax\n",
    "\n",
    "**Benefits:**\n",
    "- Prevents training instability\n",
    "- Prevents signal explosion/collapse\n",
    "- Better scaling to large models\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "1. Does mHC help with grokking on modular addition?\n",
    "2. Does mHC prevent the 0% test accuracy issue?\n",
    "3. Does mHC lead to different LLC trajectories?\n",
    "4. Is the learned solution simpler (lower LLC) or more complex (higher LLC)?\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Using the PyTorch implementation from: https://github.com/tokenbender/mHC-manifold-constrained-hyper-connections\n",
    "\n",
    "Paper: https://arxiv.org/abs/2512.24880"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install devinterp scipy einops torch\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "from einops import rearrange, einsum\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from devinterp.optim.sgld import SGLD\n",
    "from devinterp.slt.sampler import estimate_learning_coeff_with_summary\n",
    "from devinterp.utils import evaluate_ce\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESULTS_DIR = Path(\"../results/mhc_grokking\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    fig.savefig(RESULTS_DIR / name, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Results: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mhc_impl",
   "metadata": {},
   "source": [
    "## 2. mHC Implementation (from GitHub repo)\n",
    "\n",
    "Simplified version adapted for our modular addition task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mhc_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mHC helper functions\n",
    "\n",
    "def exists(v):\n",
    "    return v is not None\n",
    "\n",
    "def default(v, d):\n",
    "    return v if exists(v) else d\n",
    "\n",
    "def sinkhorn_log(logits, num_iters=10, tau=0.05):\n",
    "    \"\"\"Sinkhorn-Knopp algorithm in log-space for numerical stability.\n",
    "    \n",
    "    Projects a matrix onto the doubly stochastic manifold (Birkhoff polytope).\n",
    "    Result has non-negative entries where rows and columns sum to 1.\n",
    "    \n",
    "    Args:\n",
    "        logits: Input matrix\n",
    "        num_iters: Number of Sinkhorn iterations (default: 10)\n",
    "        tau: Temperature parameter (default: 0.05)\n",
    "    \n",
    "    Returns:\n",
    "        Doubly stochastic matrix\n",
    "    \"\"\"\n",
    "    n = logits.shape[-1]\n",
    "    Z = logits / tau\n",
    "    log_marginal = torch.zeros((n,), device=logits.device, dtype=logits.dtype)\n",
    "    \n",
    "    u = torch.zeros(logits.shape[:-1], device=Z.device, dtype=Z.dtype)\n",
    "    v = torch.zeros_like(u)\n",
    "    \n",
    "    # Iteratively normalize rows and columns\n",
    "    for _ in range(num_iters):\n",
    "        u = log_marginal - torch.logsumexp(Z + v.unsqueeze(-2), dim=-1)\n",
    "        v = log_marginal - torch.logsumexp(Z + u.unsqueeze(-1), dim=-2)\n",
    "    \n",
    "    return torch.exp(Z + u.unsqueeze(-1) + v.unsqueeze(-2))\n",
    "\n",
    "\n",
    "class SimpleHyperConnection(nn.Module):\n",
    "    \"\"\"Simplified mHC layer for combining two inputs (left and right embeddings).\n",
    "    \n",
    "    Instead of: x = x_left + x_right (standard addition)\n",
    "    We use:     x = H_res @ [x_left, x_right] (learnable weighted combination)\n",
    "    \n",
    "    Where H_res is constrained to be doubly stochastic via Sinkhorn-Knopp.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim, num_streams=2, mhc_num_iters=20, mhc_tau=0.05):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_streams = num_streams\n",
    "        self.mhc_num_iters = mhc_num_iters\n",
    "        self.mhc_tau = mhc_tau\n",
    "        \n",
    "        # Initialize H_res_logits\n",
    "        # Start with near-identity: diagonal = 0, off-diagonal = -8\n",
    "        # After sinkhorn, this becomes approximately I (identity)\n",
    "        init_h_res = torch.full((num_streams, num_streams), -8.0)\n",
    "        init_h_res.fill_diagonal_(0.0)\n",
    "        self.H_res_logits = nn.Parameter(init_h_res)\n",
    "    \n",
    "    def forward(self, x_left, x_right):\n",
    "        \"\"\"Combine left and right inputs using doubly stochastic mixing.\n",
    "        \n",
    "        Args:\n",
    "            x_left: [batch, dim] - left embedding\n",
    "            x_right: [batch, dim] - right embedding\n",
    "        \n",
    "        Returns:\n",
    "            [batch, dim] - mixed output\n",
    "        \"\"\"\n",
    "        batch_size = x_left.shape[0]\n",
    "        \n",
    "        # Stack inputs: [batch, 2, dim]\n",
    "        x_stacked = torch.stack([x_left, x_right], dim=1)\n",
    "        \n",
    "        # Apply Sinkhorn to get doubly stochastic matrix\n",
    "        H_res = sinkhorn_log(\n",
    "            self.H_res_logits, \n",
    "            num_iters=self.mhc_num_iters, \n",
    "            tau=self.mhc_tau\n",
    "        )\n",
    "        \n",
    "        # Mix: [2, 2] @ [batch, 2, dim] -> [batch, 2, dim]\n",
    "        # We want to combine the 2 streams into 1, so take first stream output\n",
    "        x_mixed = einsum(H_res[0], x_stacked, 's, b s d -> b d')\n",
    "        \n",
    "        return x_mixed\n",
    "\n",
    "\n",
    "print(\"✅ mHC implementation loaded!\")\n",
    "\n",
    "# Quick test\n",
    "test_layer = SimpleHyperConnection(dim=16)\n",
    "x_l = torch.randn(4, 16)\n",
    "x_r = torch.randn(4, 16)\n",
    "out = test_layer(x_l, x_r)\n",
    "print(f\"Test successful: input shapes ({x_l.shape}, {x_r.shape}) -> output shape {out.shape}\")\n",
    "\n",
    "# Verify doubly stochastic property\n",
    "with torch.no_grad():\n",
    "    H = sinkhorn_log(test_layer.H_res_logits)\n",
    "    print(f\"\\nDoubly stochastic verification:\")\n",
    "    print(f\"  Row sums: {H.sum(dim=1).numpy()}\")\n",
    "    print(f\"  Col sums: {H.sum(dim=0).numpy()}\")\n",
    "    print(f\"  All close to 1.0? {torch.allclose(H.sum(dim=1), torch.ones(2), atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models",
   "metadata": {},
   "source": [
    "## 3. Model Architectures\n",
    "\n",
    "Baseline MLP vs MLP with mHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineMLP(nn.Module):\n",
    "    \"\"\"Standard MLP for modular addition (baseline).\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim=12, hidden_size=48):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear1l = nn.Linear(embed_dim, hidden_size, bias=True)\n",
    "        self.linear1r = nn.Linear(embed_dim, hidden_size, bias=True)\n",
    "        self.act = nn.GELU()\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.embedding.weight.device)\n",
    "        x1 = self.embedding(x[..., 0])\n",
    "        x2 = self.embedding(x[..., 1])\n",
    "        x1 = self.linear1l(x1)\n",
    "        x2 = self.linear1r(x2)\n",
    "        x = x1 + x2  # Standard addition\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLPWithMHC(nn.Module):\n",
    "    \"\"\"MLP with mHC for combining left/right embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim=12, hidden_size=48, \n",
    "                 mhc_num_iters=20, mhc_tau=0.05):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear1l = nn.Linear(embed_dim, hidden_size, bias=True)\n",
    "        self.linear1r = nn.Linear(embed_dim, hidden_size, bias=True)\n",
    "        \n",
    "        # mHC layer to combine left and right\n",
    "        self.mhc = SimpleHyperConnection(\n",
    "            dim=hidden_size,\n",
    "            num_streams=2,\n",
    "            mhc_num_iters=mhc_num_iters,\n",
    "            mhc_tau=mhc_tau\n",
    "        )\n",
    "        \n",
    "        self.act = nn.GELU()\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.embedding.weight.device)\n",
    "        x1 = self.embedding(x[..., 0])\n",
    "        x2 = self.embedding(x[..., 1])\n",
    "        x1 = self.linear1l(x1)\n",
    "        x2 = self.linear1r(x2)\n",
    "        \n",
    "        # Use mHC instead of simple addition\n",
    "        x = self.mhc(x1, x2)  # Learnable doubly stochastic mixing!\n",
    "        \n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compare parameter counts\n",
    "baseline = BaselineMLP(vocab_size=64)\n",
    "mhc_model = MLPWithMHC(vocab_size=64)\n",
    "\n",
    "baseline_params = sum(p.numel() for p in baseline.parameters())\n",
    "mhc_params = sum(p.numel() for p in mhc_model.parameters())\n",
    "\n",
    "print(f\"Baseline MLP parameters: {baseline_params:,}\")\n",
    "print(f\"MLP with mHC parameters: {mhc_params:,}\")\n",
    "print(f\"Overhead: {mhc_params - baseline_params:,} (+{100*(mhc_params-baseline_params)/baseline_params:.2f}%)\")\n",
    "print(f\"\\n(mHC adds a 2×2 learnable mixing matrix = 4 parameters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils",
   "metadata": {},
   "source": [
    "## 4. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def test(model, dataset, device):\n",
    "    n_correct = 0\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataset:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            total_loss += loss.item()\n",
    "            pred = torch.argmax(out, dim=-1)\n",
    "            if pred == y:\n",
    "                n_correct += 1\n",
    "    return n_correct / len(dataset), total_loss / len(dataset)\n",
    "\n",
    "def train(train_dataset, test_dataset, model, params, verbose=True):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), weight_decay=params.weight_decay, lr=params.lr\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params.batch_size, shuffle=True)\n",
    "    \n",
    "    print_every = params.n_batches // params.print_times\n",
    "    checkpoint_every = params.n_batches // params.n_checkpoints\n",
    "    \n",
    "    all_models = []\n",
    "    loss_data = []\n",
    "    \n",
    "    if verbose:\n",
    "        pbar = tqdm(total=params.n_batches, desc=\"Training\")\n",
    "    \n",
    "    for i in range(params.n_batches):\n",
    "        batch = next(iter(train_loader))\n",
    "        X, Y = batch\n",
    "        X, Y = X.to(params.device), Y.to(params.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = loss_fn(out, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % checkpoint_every == 0:\n",
    "            all_models.append(deepcopy(model))\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            val_acc, val_loss = test(model, test_dataset, params.device)\n",
    "            train_acc, train_loss = test(model, train_dataset, params.device)\n",
    "            loss_data.append({\n",
    "                \"batch\": i + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "            })\n",
    "            if verbose:\n",
    "                pbar.set_postfix({\n",
    "                    \"train_acc\": f\"{train_acc:.4f}\",\n",
    "                    \"val_acc\": f\"{val_acc:.4f}\",\n",
    "                })\n",
    "                pbar.update(print_every)\n",
    "    \n",
    "    if verbose:\n",
    "        pbar.close()\n",
    "    \n",
    "    df = pd.DataFrame(loss_data)\n",
    "    return all_models, df\n",
    "\n",
    "def make_dataset(modulus, max_input_val):\n",
    "    \"\"\"Create dataset for modular addition.\n",
    "    \n",
    "    Args:\n",
    "        modulus: The modulus for the operation (e.g., 64)\n",
    "        max_input_val: Maximum value for inputs a,b (e.g., 63 for full task)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for a in range(max_input_val + 1):\n",
    "        for b in range(max_input_val + 1):\n",
    "            x = torch.tensor([a, b])\n",
    "            y = torch.tensor((a + b) % modulus)\n",
    "            data.append((x, y))\n",
    "    return data\n",
    "\n",
    "def train_test_split(dataset, train_frac, seed):\n",
    "    n = len(dataset)\n",
    "    n_train = int(train_frac * n)\n",
    "    indices = list(range(n))\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(indices)\n",
    "    train_idx = indices[:n_train]\n",
    "    test_idx = indices[n_train:]\n",
    "    return [dataset[i] for i in train_idx], [dataset[i] for i in test_idx]\n",
    "\n",
    "print(\"Training utilities defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "params",
   "metadata": {},
   "source": [
    "## 5. Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "params_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Params:\n",
    "    modulus: int = 64\n",
    "    n_batches: int = 100000  # More training for grokking\n",
    "    n_checkpoints: int = 100\n",
    "    print_times: int = 100\n",
    "    lr: float = 0.001  # Slightly lower LR for stability\n",
    "    batch_size: int = 128\n",
    "    embed_dim: int = 12\n",
    "    hidden_size: int = 48\n",
    "    weight_decay: float = 1.0  # Higher for grokking\n",
    "    device: str = DEVICE\n",
    "\n",
    "SEEDS = [0, 1, 2]  # Run 3 seeds\n",
    "\n",
    "# Create dataset (full mod-64 task)\n",
    "dataset = make_dataset(modulus=64, max_input_val=63)\n",
    "train_data, test_data = train_test_split(dataset, train_frac=0.3, seed=0)\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} pairs total\")\n",
    "print(f\"Train: {len(train_data)} pairs ({100*len(train_data)/len(dataset):.1f}%)\")\n",
    "print(f\"Test: {len(test_data)} pairs ({100*len(test_data)/len(dataset):.1f}%)\")\n",
    "print(f\"\\nTraining for {Params().n_batches:,} batches with {len(SEEDS)} seeds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_baseline",
   "metadata": {},
   "source": [
    "## 6. Run Baseline MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"BASELINE MLP - SEED {seed}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    set_seed(seed)\n",
    "    params = Params()\n",
    "    \n",
    "    model = BaselineMLP(\n",
    "        vocab_size=params.modulus,\n",
    "        embed_dim=params.embed_dim,\n",
    "        hidden_size=params.hidden_size\n",
    "    ).to(params.device)\n",
    "    \n",
    "    train_ds = [(x.to(DEVICE), y.to(DEVICE)) for x, y in train_data]\n",
    "    test_ds = [(x.to(DEVICE), y.to(DEVICE)) for x, y in test_data]\n",
    "    \n",
    "    checkpoints, df = train(train_ds, test_ds, model, params, verbose=True)\n",
    "    baseline_results[seed] = {'checkpoints': checkpoints, 'df': df}\n",
    "\n",
    "print(\"\\n✅ Baseline training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_mhc",
   "metadata": {},
   "source": [
    "## 7. Run MLP with mHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mhc_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhc_results = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"MLP WITH mHC - SEED {seed}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    set_seed(seed)\n",
    "    params = Params()\n",
    "    \n",
    "    model = MLPWithMHC(\n",
    "        vocab_size=params.modulus,\n",
    "        embed_dim=params.embed_dim,\n",
    "        hidden_size=params.hidden_size,\n",
    "        mhc_num_iters=20,\n",
    "        mhc_tau=0.05\n",
    "    ).to(params.device)\n",
    "    \n",
    "    train_ds = [(x.to(DEVICE), y.to(DEVICE)) for x, y in train_data]\n",
    "    test_ds = [(x.to(DEVICE), y.to(DEVICE)) for x, y in test_data]\n",
    "    \n",
    "    checkpoints, df = train(train_ds, test_ds, model, params, verbose=True)\n",
    "    mhc_results[seed] = {'checkpoints': checkpoints, 'df': df}\n",
    "\n",
    "print(\"\\n✅ mHC training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot_results",
   "metadata": {},
   "source": [
    "## 8. Compare Training Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across seeds\n",
    "def aggregate_dfs(results_dict):\n",
    "    all_dfs = [results_dict[seed]['df'] for seed in SEEDS]\n",
    "    min_len = min(len(df) for df in all_dfs)\n",
    "    \n",
    "    metrics = {}\n",
    "    for col in ['train_acc', 'val_acc', 'train_loss', 'val_loss']:\n",
    "        values = np.array([df[col].values[:min_len] for df in all_dfs])\n",
    "        metrics[col + '_mean'] = np.mean(values, axis=0)\n",
    "        metrics[col + '_std'] = np.std(values, axis=0)\n",
    "    return metrics, min_len\n",
    "\n",
    "baseline_metrics, _ = aggregate_dfs(baseline_results)\n",
    "mhc_metrics, _ = aggregate_dfs(mhc_results)\n",
    "\n",
    "# Plot test accuracy\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(baseline_metrics['val_acc_mean']))\n",
    "\n",
    "# Baseline\n",
    "ax.plot(x, baseline_metrics['val_acc_mean'], label='Baseline MLP', color='blue', linewidth=2)\n",
    "ax.fill_between(x,\n",
    "                baseline_metrics['val_acc_mean'] - baseline_metrics['val_acc_std'],\n",
    "                baseline_metrics['val_acc_mean'] + baseline_metrics['val_acc_std'],\n",
    "                alpha=0.3, color='blue')\n",
    "\n",
    "# mHC\n",
    "ax.plot(x, mhc_metrics['val_acc_mean'], label='MLP with mHC', color='orange', linewidth=2)\n",
    "ax.fill_between(x,\n",
    "                mhc_metrics['val_acc_mean'] - mhc_metrics['val_acc_std'],\n",
    "                mhc_metrics['val_acc_mean'] + mhc_metrics['val_acc_std'],\n",
    "                alpha=0.3, color='orange')\n",
    "\n",
    "ax.set_xlabel('Checkpoint', fontsize=12)\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax.set_title(f'Grokking: Baseline vs mHC (mean ± std, n={len(SEEDS)} seeds)', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "save_fig(fig, 'baseline_vs_mhc_accuracy.png')\n",
    "\n",
    "# Plot generalization gap (train - test accuracy)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "baseline_gap = baseline_metrics['train_acc_mean'] - baseline_metrics['val_acc_mean']\n",
    "mhc_gap = mhc_metrics['train_acc_mean'] - mhc_metrics['val_acc_mean']\n",
    "\n",
    "ax.plot(x, baseline_gap, label='Baseline Gap', color='blue', linewidth=2)\n",
    "ax.plot(x, mhc_gap, label='mHC Gap', color='orange', linewidth=2)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.3, label='Perfect Generalization')\n",
    "\n",
    "ax.set_xlabel('Checkpoint', fontsize=12)\n",
    "ax.set_ylabel('Generalization Gap (Train - Test Acc)', fontsize=12)\n",
    "ax.set_title('Generalization Gap: Baseline vs mHC', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "save_fig(fig, 'generalization_gap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats",
   "metadata": {},
   "source": [
    "## 9. Statistical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare final test accuracy\n",
    "baseline_final = [baseline_results[seed]['df']['val_acc'].iloc[-1] for seed in SEEDS]\n",
    "mhc_final = [mhc_results[seed]['df']['val_acc'].iloc[-1] for seed in SEEDS]\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(baseline_final, mhc_final)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFinal Test Accuracy (n={len(SEEDS)} seeds):\")\n",
    "print(f\"  Baseline: {np.mean(baseline_final):.4f} ± {np.std(baseline_final):.4f}\")\n",
    "print(f\"  mHC:      {np.mean(mhc_final):.4f} ± {np.std(mhc_final):.4f}\")\n",
    "print(f\"\\nTwo-sample t-test:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value:     {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\n✅ Difference is statistically significant (p < 0.05)\")\n",
    "    if np.mean(mhc_final) > np.mean(baseline_final):\n",
    "        print(\"   mHC performs BETTER than baseline\")\n",
    "    else:\n",
    "        print(\"   mHC performs WORSE than baseline\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No significant difference (p >= 0.05)\")\n",
    "\n",
    "# Cohen's d\n",
    "pooled_std = np.sqrt((np.var(baseline_final) + np.var(mhc_final)) / 2)\n",
    "cohens_d = (np.mean(mhc_final) - np.mean(baseline_final)) / pooled_std\n",
    "print(f\"\\nEffect size (Cohen's d): {cohens_d:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llc",
   "metadata": {},
   "source": [
    "## 10. LLC Estimation (Seed 0 Only)\n",
    "\n",
    "Due to computational cost, we estimate LLC for seed 0 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llc_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLC hyperparameters\n",
    "llc_params = {\n",
    "    'lr': 3e-3,\n",
    "    'nbeta': 2.0,\n",
    "    'gamma': 10.0,  # Adjusted for mod-64\n",
    "    'num_chains': 3,\n",
    "    'num_draws': 1000,\n",
    "}\n",
    "\n",
    "seed = 0\n",
    "train_loader = DataLoader(\n",
    "    [(x.to(DEVICE), y.to(DEVICE)) for x, y in train_data],\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Estimate LLC for baseline (sample every 10th checkpoint)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LLC ESTIMATION - BASELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_checkpoints = baseline_results[seed]['checkpoints']\n",
    "baseline_llcs = []\n",
    "\n",
    "for i in range(0, len(baseline_checkpoints), 10):\n",
    "    print(f\"Checkpoint {i+1}/{len(baseline_checkpoints)}\")\n",
    "    llc_stats = estimate_learning_coeff_with_summary(\n",
    "        baseline_checkpoints[i],\n",
    "        loader=train_loader,\n",
    "        evaluate=evaluate_ce,\n",
    "        sampling_method=SGLD,\n",
    "        optimizer_kwargs=dict(\n",
    "            lr=llc_params['lr'],\n",
    "            nbeta=llc_params['nbeta'],\n",
    "            localization=llc_params['gamma']\n",
    "        ),\n",
    "        num_chains=llc_params['num_chains'],\n",
    "        num_draws=llc_params['num_draws'],\n",
    "        device=DEVICE,\n",
    "        online=False,\n",
    "    )\n",
    "    baseline_llcs.append(llc_stats)\n",
    "\n",
    "# Estimate LLC for mHC\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LLC ESTIMATION - mHC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mhc_checkpoints = mhc_results[seed]['checkpoints']\n",
    "mhc_llcs = []\n",
    "\n",
    "for i in range(0, len(mhc_checkpoints), 10):\n",
    "    print(f\"Checkpoint {i+1}/{len(mhc_checkpoints)}\")\n",
    "    llc_stats = estimate_learning_coeff_with_summary(\n",
    "        mhc_checkpoints[i],\n",
    "        loader=train_loader,\n",
    "        evaluate=evaluate_ce,\n",
    "        sampling_method=SGLD,\n",
    "        optimizer_kwargs=dict(\n",
    "            lr=llc_params['lr'],\n",
    "            nbeta=llc_params['nbeta'],\n",
    "            localization=llc_params['gamma']\n",
    "        ),\n",
    "        num_chains=llc_params['num_chains'],\n",
    "        num_draws=llc_params['num_draws'],\n",
    "        device=DEVICE,\n",
    "        online=False,\n",
    "    )\n",
    "    mhc_llcs.append(llc_stats)\n",
    "\n",
    "print(\"\\n✅ LLC estimation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot_llc",
   "metadata": {},
   "source": [
    "## 11. Plot LLC Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_llc_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_llc_values = [llc['llc/mean'] for llc in baseline_llcs]\n",
    "mhc_llc_values = [llc['llc/mean'] for llc in mhc_llcs]\n",
    "\n",
    "# Get corresponding accuracy values (sampled every 10th)\n",
    "baseline_df = baseline_results[seed]['df']\n",
    "mhc_df = mhc_results[seed]['df']\n",
    "\n",
    "baseline_acc_sampled = baseline_df['val_acc'].values[::10]\n",
    "mhc_acc_sampled = mhc_df['val_acc'].values[::10]\n",
    "\n",
    "# Plot LLC vs Accuracy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Baseline\n",
    "color = 'blue'\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1.plot(baseline_acc_sampled, label='Test Acc', color=color)\n",
    "ax1_twin.plot(baseline_llc_values, label='LLC', color='green', linewidth=2)\n",
    "ax1.set_xlabel('Checkpoint (×10)', fontsize=11)\n",
    "ax1.set_ylabel('Test Accuracy', color=color, fontsize=11)\n",
    "ax1_twin.set_ylabel('LLC (λ̂)', color='green', fontsize=11)\n",
    "ax1.set_title('Baseline MLP: LLC vs Accuracy', fontsize=12)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1_twin.tick_params(axis='y', labelcolor='green')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# mHC\n",
    "color = 'orange'\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2.plot(mhc_acc_sampled, label='Test Acc', color=color)\n",
    "ax2_twin.plot(mhc_llc_values, label='LLC', color='green', linewidth=2)\n",
    "ax2.set_xlabel('Checkpoint (×10)', fontsize=11)\n",
    "ax2.set_ylabel('Test Accuracy', color=color, fontsize=11)\n",
    "ax2_twin.set_ylabel('LLC (λ̂)', color='green', fontsize=11)\n",
    "ax2.set_title('MLP with mHC: LLC vs Accuracy', fontsize=12)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2_twin.tick_params(axis='y', labelcolor='green')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(fig, 'llc_vs_accuracy.png')\n",
    "\n",
    "# Direct LLC comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(baseline_llc_values, label='Baseline MLP', color='blue', linewidth=2)\n",
    "ax.plot(mhc_llc_values, label='MLP with mHC', color='orange', linewidth=2)\n",
    "ax.set_xlabel('Checkpoint (×10)', fontsize=12)\n",
    "ax.set_ylabel('LLC (λ̂)', fontsize=12)\n",
    "ax.set_title('LLC Trajectories: Baseline vs mHC', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "save_fig(fig, 'llc_comparison.png')\n",
    "\n",
    "print(\"\\nLLC Summary:\")\n",
    "print(f\"Baseline - Initial: {baseline_llc_values[0]:.2f}, Final: {baseline_llc_values[-1]:.2f}\")\n",
    "print(f\"mHC      - Initial: {mhc_llc_values[0]:.2f}, Final: {mhc_llc_values[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "This experiment compared:\n",
    "- **Baseline MLP**: Standard addition to combine embeddings\n",
    "- **MLP with mHC**: Doubly stochastic mixing via Sinkhorn-Knopp\n",
    "\n",
    "Key findings:\n",
    "1. Training stability (did mHC prevent 0% test accuracy?)\n",
    "2. Grokking behavior (faster/slower generalization?)\n",
    "3. LLC evolution (simpler/more complex solutions?)\n",
    "4. Final performance comparison\n",
    "\n",
    "All results saved to: `{RESULTS_DIR}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
